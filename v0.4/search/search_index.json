{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#what-is-zora","title":"What is Zora?","text":"<p>Zora is a multi-cluster scan that helps you to identify potential issues and vulnerabilities  in your Kubernetes clusters in a centralized way, ensuring that the recommended best practices are in place.</p> <p>Throughout this documentation, we will use the following notation:</p> <ul> <li>Management Cluster to refer to the only Kubernetes cluster where Zora is installed;</li> <li>Target Cluster to refer to all clusters you will connect to Zora to be scanned.</li> </ul> <p>Follow these steps to get started with Zora:</p> <ol> <li> <p>Install Zora in a Management Cluster</p> </li> <li> <p>Prepare the target cluster by creating a service account and generating a kubeconfig</p> </li> <li> <p>Connect the target cluster to Zora</p> </li> <li> <p>Configure a scan for the target cluster</p> </li> <li> <p>After a successful scan checkout the potential reported issues</p> </li> </ol> <p>All the information about these steps are detailed throughout this documentation.</p>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#zora-origins","title":"Zora origins","text":"<p>In the early days of the cloud native era, Borg dominated the container-oriented cluster management scene. The origin of the name Borg refers to the cybernetic life form existing in the Star Trek series,  that worked as a collective of individuals with a single mind and the same purpose, as well as a \"cluster\".</p> <p>As good nerds as we are and wishing to honor our Kubernetes' predecessor (Borg) we named our project Zora.</p> <p>In Star Trek, Zora is the Artificial Intelligence that controls the ship U.S.S Discovery. After being merged with a collective of other intelligences, Zora became sentient and became a member of the team, bringing insights and making the ship more efficient.</p> <p>Like Star Trek's Zora, our goal is to help manage your K8s environment by periodically scanning all of your clusters,  looking for potential issues or vulnerabilities with deployed features and configurations, and helping you ensure compliance with the best practices.</p>"},{"location":"cluster-scan/","title":"Configure a cluster scan","text":"<p>Since your clusters are connected the next and last step is configure a scan for them by creating a <code>ClusterScan</code> in the same namespace as <code>Cluster</code> resource.</p> <p>The <code>ClusterScan</code> will be responsible for reporting issues and vulnerabilities of your clusters.</p> <p>Failure to perform this step implies that the scan will not be performed, and therefore the health of your cluster will be unknown.</p>"},{"location":"cluster-scan/#create-a-clusterscan","title":"Create a <code>ClusterScan</code>","text":"<p>The <code>ClusterScan</code> scans the <code>Cluster</code> referenced in <code>clusterRef.name</code> field periodically on a given schedule,  written in Cron format.</p> <p>Here is a sample configuration that scan <code>mycluster</code> once an hour. You can modify putting your desired periodicity.</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: zora.undistro.io/v1alpha1\nkind: ClusterScan\nmetadata:\n  name: mycluster\nspec:\n  clusterRef:\n    name: mycluster\n  schedule: \"0 */1 * * *\"\nEOF\n</code></pre>"},{"location":"cluster-scan/#cron-schedule-syntax","title":"Cron schedule syntax","text":"<p>Cron expression has five fields separated by a space, and each field represents a time unit.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday;\n\u2502 \u2502 \u2502 \u2502 \u2502                                   7 is also Sunday on some systems)\n\u2502 \u2502 \u2502 \u2502 \u2502                                   OR sun, mon, tue, wed, thu, fri, sat\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n</code></pre>    Operator Descriptor Example     * Any value <code>15 * * * *</code> runs at every minute 15 of every hour of every day.   , Value list separator <code>2,10 4,5 * * *</code> runs at minute 2 and 10 of the 4th and 5th hour of every day.   - Range of values <code>30 4-6 * * *</code> runs at minute 30 of the 4th, 5th, and 6th hour.   / Step values <code>20/15 * * * *</code> runs every 15 minutes starting from minute 20 through 59 (minutes 20, 35, and 50).    <p>Now Zora is ready to help you to identify potential issues and vulnerabilities in your kubernetes clusters.</p> <p>You can check the scans status and the reported issues by the following steps:</p>"},{"location":"cluster-scan/#list-cluster-scans","title":"List cluster scans","text":"<p>Listing the <code>ClusterScans</code>, the information of the last scans are available:</p> <pre><code>kubectl get clusterscan -o wide\nNAME        CLUSTER     SCHEDULE      SUSPEND   PLUGINS   LAST STATUS   LAST SCHEDULE   LAST SUCCESSFUL   ISSUES   READY   AGE   NEXT SCHEDULE\nmycluster   mycluster   0 */1 * * *   false     popeye    Complete      12m             14m               21       True    32d   2022-06-27T23:00:00Z\n</code></pre> <p>The <code>LAST STATUS</code> column represents the status (Active, Complete or Failed) of the last scan  that was scheduled at the time represented by <code>LAST SCHEDULE</code> column.</p>"},{"location":"cluster-scan/#list-cluster-issues","title":"List cluster issues","text":"<p>Once the cluster is successfully scanned, the reported issues are available in <code>ClusterIssue</code> resources:</p> <pre><code>kubectl get clusterissues -l cluster=mycluster\nNAME                          CLUSTER      ID         MESSAGE                                                                        SEVERITY   CATEGORY          AGE\nmycluster-pop-102-27557035    mycluster    POP-102    No probes defined                                                              Medium     pods              4m8s\nmycluster-pop-105-27557035    mycluster    POP-105    Liveness probe uses a port#, prefer a named port                               Low        pods              4m8s\nmycluster-pop-106-27557035    mycluster    POP-106    No resources requests/limits defined                                           Medium     daemonsets        4m8s\nmycluster-pop-1100-27557035   mycluster    POP-1100   No pods match service selector                                                 High       services          4m8s\nmycluster-pop-306-27557035    mycluster    POP-306    Container could be running as root user. Check SecurityContext/Image           Medium     pods              4m8s\nmycluster-pop-500-27557035    mycluster    POP-500    Zero scale detected                                                            Medium     deployments       4m8s\n</code></pre> <p>It's possible filter issues by cluster, issue ID, severity and category  using label selector:</p> <pre><code># issues from mycluster\nkubectl get clusterissues -l cluster=mycluster\n\n# clusters with issue POP-106\nkubectl get clusterissues -l id=POP-106\n\n# issues from mycluster with high severity\nkubectl get clusterissues -l cluster=mycluster,severity=High\n\n# only issues reported by the last scan from mycluster\nkubectl get clusterissues -l cluster=mycluster,scanID=fa4e63cc-5236-40f3-aa7f-599e1c83208b\n</code></pre>  <p>Why is it an issue?</p> <p>The field <code>url</code> in <code>ClusterIssue</code> spec represents a link for a documentation about this issue. It is displayed in the UI and you can see by <code>kubectl</code> with the <code>-o=yaml</code> flag or the command below.</p> <pre><code>kubectl get clusterissues -o=custom-columns=\"NAME:.metadata.name,MESSAGE:.spec.message,URL:.spec.url\"\nNAME                          MESSAGE                                                                        URL\nmycluster-pop-102-27557035    No probes defined                                                              https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\nmycluster-pop-105-27557035    Liveness probe uses a port#, prefer a named port                               &lt;none&gt;\nmycluster-pop-106-27557035    No resources requests/limits defined                                           https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\nmycluster-pop-1100-27557035   No pods match service selector                                                 https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service\nmycluster-pop-306-27557035    Container could be running as root user. Check SecurityContext/Image           https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted\nmycluster-pop-500-27557035    Zero scale detected                                                            https://kubernetes.io/docs/concepts/workloads/\n</code></pre> <p>These docs should help you understand why it's an issue and how to fix it.</p> <p>All URLs are available here  and you can contribute to Zora adding new links. See our contribution guidelines.</p>"},{"location":"connect-cluster/","title":"Connect the target cluster to Zora","text":"<p>After preparing your target clusters, you need to connect them directly to Zora by  following the instructions below.</p>"},{"location":"connect-cluster/#prerequisites","title":"Prerequisites","text":"<ol> <li>A kubeconfig file with an authentication <code>token</code> of the target cluster.     Follow these instructions to generate it.</li> <li>The api-server     of the target cluster     must be reachable by the management cluster. </li> </ol> <p>Without the prerequisites Zora will not be able to connect to the target cluster and will set a failure status.</p>  <p>Metrics Server</p> <p>If the target cluster hasn't Metrics Server deployed,  information about the usage of memory and CPU won't be collected and issues about potential resources over/under allocations won't be reported.</p> <p>For more information about Metrics Server, visit the official documentation.</p>"},{"location":"connect-cluster/#1-access-the-management-cluster","title":"1. Access the management cluster","text":"<p>First, make sure you are in the context of the management cluster. You can do this by the following commands:</p> <ul> <li> <p>Display list of contexts: <code>kubectl config get-contexts</code></p> </li> <li> <p>Display the current-context: <code>kubectl config current-context</code></p> </li> <li> <p>Set the default context to my-management-cluster: <code>kubectl config use-context my-management-cluster</code></p> </li> </ul>"},{"location":"connect-cluster/#2-create-a-cluster-resource","title":"2. Create a <code>Cluster</code> resource","text":"<p>First, create a <code>Secret</code> with the content of the kubeconfig file:</p> <pre><code>kubectl create secret generic mycluster-kubeconfig \\\n  -n zora-system \\\n  --from-file=value=zora-view-kubeconfig.yml\n</code></pre> <p>Now, you are able to create a <code>Cluster</code> resource referencing the kubeconfig Secret in the same namespace:</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: zora.undistro.io/v1alpha1\nkind: Cluster\nmetadata:\n  name: mycluster\n  namespace: zora-system\n  labels:\n    zora.undistro.io/environment: prod\nspec:\n  kubeconfigRef:\n    name: mycluster-kubeconfig\nEOF\n</code></pre> <p>If you've made it this far, congratulations, your clusters are connected. Now you can list them and see the discovered data through <code>kubectl</code>:</p>"},{"location":"connect-cluster/#list-clusters","title":"List clusters","text":"<pre><code>kubectl get clusters -o wide\nNAME        VERSION               MEM AVAILABLE   MEM USAGE (%)   CPU AVAILABLE   CPU USAGE (%)   NODES   READY   AGE   PROVIDER   REGION   \nmycluster   v1.21.5-eks-bc4871b   10033Mi         3226Mi (32%)    5790m           647m (11%)      3       True    40d   aws        us-east-1\n</code></pre>  <p>Tip</p> <ul> <li>Get clusters from all namespaces using <code>--all-namespaces</code> flag</li> <li>Get clusters with additional information using <code>-o=wide</code> flag</li> <li>Get the documentation for <code>clusters</code> manifests using <code>kubectl explain clusters</code></li> <li>Get cluster from <code>prod</code> environment using <code>kubectl get clusters -l zora.undistro.io/environment=prod</code></li> </ul>  <p>The cluster list output has the following columns:</p> <ul> <li><code>NAME</code>: Cluster name</li> <li><code>VERSION</code>: Kubernetes version</li> <li><code>MEM AVAILABLE</code>: Quantity of memory available (requires Metrics Server)</li> <li><code>MEM USAGE (%)</code>: Usage of memory in quantity and percentage (requires Metrics Server)</li> <li><code>CPU AVAILABLE</code>: Quantity of CPU available (requires Metrics Server)</li> <li><code>CPU USAGE (%)</code>: Usage of CPU in quantity and percentage (requires Metrics Server)</li> <li><code>NODES</code>: Total of nodes</li> <li><code>READY</code>: Indicates whether the cluster is connected</li> <li><code>AGE</code>: Age of the kube-system namespace in cluster</li> <li><code>PROVIDER</code>: Cluster provider (with <code>-o=wide</code> flag)</li> <li><code>REGION</code>: Cluster region (<code>multi-region</code> if nodes have different <code>topology.kubernetes.io/region</code> label)   (with <code>-o=wide</code> flag)</li> </ul>  <p>Provider</p> <p>The value in <code>PROVIDER</code> column is obtained by matching the Node's labels (e.g., a Node with label key prefix <code>eks.amazonaws.com/</code> means that the provider of this cluster is <code>aws</code>).</p> <p>For now, Zora recognizes only the providers in this list. But you can connect clusters of any provider.  If the provider isn't in this list, the column will not be filled and Zora will continue to work normally.</p> <p>Fell free to contribute to the project and add new labels prefixes for providers.  See our contribution guidelines.</p>   <p>Info</p> <ul> <li>The quantity of available and in use resources, is a sum of all Nodes.</li> <li>Only one provider is displayed in <code>PROVIDER</code> column. Different information can be displayed for multi-cloud clusters.</li> <li>Show detailed description of a cluster, including events, running <code>kubectl describe cluster mycluster</code>.</li> </ul>"},{"location":"connect-cluster/#delete-a-cluster","title":"Delete a Cluster","text":"<p>To delete a Cluster, use the following command:</p> <pre><code>kubectl delete cluster mycluster -n zora-system\n</code></pre> <p>This command deletes the <code>mycluster</code> Cluster and its scans and issues.</p>  <p>Deleting a Cluster from dashboard (SaaS)</p> <p>If you installed Zora providing a workspace ID (Zora + SaaS) and want to delete your management cluster,  please first delete all target clusters.</p> <p>If you delete the management cluster first,  you will no longer be able to access or delete your target clusters,  which will remain on your dashboard until you contact the Undistro team by email: undistro@getup.io, so that we can proceed with the deletion.</p>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#management-cluster","title":"Management Cluster","text":"<p>The only Kubernetes cluster where Zora is installed.</p>"},{"location":"glossary/#target-cluster","title":"Target Cluster","text":"<p>The Kubernetes cluster that you connect to Zora to be scanned.</p>"},{"location":"helm-chart/","title":"Zora Helm Chart","text":"<p>  </p> <p>Zora scans multiple Kubernetes clusters and reports potential issues.</p>"},{"location":"helm-chart/#installing-the-chart","title":"Installing the Chart","text":"<p>To install the chart with the release name <code>zora</code>:</p> <pre><code>helm repo add undistro https://charts.undistro.io --force-update\nhelm upgrade --install zora undistro/zora \\\n  -n zora-system \\\n  --version 0.4.0 \\\n  --create-namespace --wait\n</code></pre>  <p>The Helm chart repository has been updated from <code>https://registry.undistro.io/chartrepo/library</code> to <code>https://charts.undistro.io</code>.</p> <p>The <code>--force-update</code> flag is needed to update the repository URL.</p>  <p>These commands deploy Zora on the Kubernetes cluster in the default configuration.</p> <p>The Parameters section lists the parameters that can be configured during installation.</p>  <p>Tips:</p> <ul> <li> <p>List all charts available in <code>undistro</code> repo using <code>helm search repo undistro</code></p> </li> <li> <p>Update <code>undistro</code> chart repository using <code>helm repo update undistro</code></p> </li> <li> <p>List all versions available of <code>undistro/zora</code> chart using <code>helm search repo undistro/zora --versions</code></p> </li> <li> <p>List all releases using <code>helm list</code></p> </li> <li> <p>Get the notes provided by <code>zora</code> release using <code>helm get notes zora -n zora-system</code></p> </li> </ul>"},{"location":"helm-chart/#uninstalling-the-chart","title":"Uninstalling the Chart","text":"<p>To uninstall/delete the <code>zora</code> release:</p> <pre><code>$ helm delete zora\n</code></pre> <p>The command removes all the Kubernetes components associated with the chart and deletes the release.</p>"},{"location":"helm-chart/#parameters","title":"Parameters","text":"<p>The following table lists the configurable parameters of the Zora chart and their default values.</p>    Key Type Default Description     nameOverride string <code>\"\"</code> String to partially override fullname template with a string (will prepend the release name)   fullnameOverride string <code>\"\"</code> String to fully override fullname template with a string   saas.workspaceID string <code>\"\"</code> Your SaaS workspace ID   saas.server string <code>\"https://zora-dashboard.undistro.io\"</code> SaaS server URL   saas.hooks.image.repository string <code>\"radial/busyboxplus\"</code> SaaS hooks image repository   saas.hooks.image.tag string <code>\"curl\"</code> SaaS hooks image tag   saas.hooks.installURL string <code>\"{{.Values.saas.server}}/zora/api/v1alpha1/workspaces/{{.Values.saas.workspaceID}}/helmreleases\"</code> SaaS install hook URL template   imageCredentials.create bool <code>false</code> Specifies whether the secret should be created by providing credentials   imageCredentials.registry string <code>\"ghcr.io\"</code> Docker registry host   imageCredentials.username string <code>\"\"</code> Docker registry username   imageCredentials.password string <code>\"\"</code> Docker registry password   imagePullSecrets list <code>[]</code> Specify docker-registry secret names as an array to be used when <code>imageCredentials.create</code> is false   operator.replicaCount int <code>1</code> Number of replicas desired of Zora operator   operator.image.repository string <code>\"ghcr.io/undistro/zora/operator\"</code> Zora operator image repository   operator.image.tag string <code>\"\"</code> Overrides the image tag whose default is the chart appVersion   operator.image.pullPolicy string <code>\"IfNotPresent\"</code> Image pull policy   operator.rbac.create bool <code>true</code> Specifies whether ClusterRoles and ClusterRoleBindings should be created   operator.rbac.serviceAccount.create bool <code>true</code> Specifies whether a service account should be created   operator.rbac.serviceAccount.annotations object <code>{}</code> Annotations to be added to service account   operator.rbac.serviceAccount.name string <code>\"\"</code> The name of the service account to use. If not set and create is true, a name is generated using the fullname template   operator.podAnnotations object <code>{\"kubectl.kubernetes.io/default-container\":\"manager\"}</code> Annotations to be added to pods   operator.podSecurityContext object <code>{\"runAsGroup\":65532,\"runAsNonRoot\":true,\"runAsUser\":65532}</code> Security Context to add to the pod   operator.securityContext object <code>{\"allowPrivilegeEscalation\":false,\"readOnlyRootFilesystem\":true}</code> Security Context to add to <code>manager</code> container   operator.metricsService.type string <code>\"ClusterIP\"</code> Type of metrics service   operator.metricsService.port int <code>8443</code> Port of metrics service   operator.serviceMonitor.enabled bool <code>false</code> Specifies whether a Prometheus <code>ServiceMonitor</code> should be enabled   operator.resources object <code>{\"limits\":{\"cpu\":\"500m\",\"memory\":\"128Mi\"},\"requests\":{\"cpu\":\"10m\",\"memory\":\"64Mi\"}}</code> Resources to add to <code>manager</code> container   operator.rbacProxy.image.repository string <code>\"gcr.io/kubebuilder/kube-rbac-proxy\"</code> <code>kube-rbac-proxy</code> image repository   operator.rbacProxy.image.tag string <code>\"v0.8.0\"</code> <code>kube-rbac-proxy</code> image tag   operator.rbacProxy.image.pullPolicy string <code>\"IfNotPresent\"</code> Image pull policy   operator.rbacProxy.securityContext object <code>{\"allowPrivilegeEscalation\":false,\"readOnlyRootFilesystem\":true}</code> Security Context to add to <code>kube-rbac-proxy</code> container   operator.rbacProxy.resources object <code>{\"limits\":{\"cpu\":\"500m\",\"memory\":\"128Mi\"},\"requests\":{\"cpu\":\"5m\",\"memory\":\"64Mi\"}}</code> Resources to add to <code>kube-rbac-proxy</code> container   operator.nodeSelector object <code>{}</code> Node selection to constrain a Pod to only be able to run on particular Node(s)   operator.tolerations list <code>[]</code> Tolerations for pod assignment   operator.affinity object <code>{}</code> Map of node/pod affinities   operator.log.encoding string <code>\"json\"</code> Log encoding (one of 'json' or 'console')   operator.log.level string <code>\"info\"</code> Log level to configure the verbosity of logging. Can be one of 'debug', 'info', 'error', or any integer value &gt; 0 which corresponds to custom debug levels of increasing verbosity   operator.log.stacktraceLevel string <code>\"error\"</code> Log level at and above which stacktraces are captured (one of 'info', 'error' or 'panic')   operator.log.timeEncoding string <code>\"rfc3339\"</code> Log time encoding (one of 'epoch', 'millis', 'nano', 'iso8601', 'rfc3339' or 'rfc3339nano')   scan.worker.image.repository string <code>\"ghcr.io/undistro/zora/worker\"</code> worker image repository   scan.worker.image.tag string <code>\"\"</code> Overrides the image tag whose default is the chart appVersion   scan.defaultPlugins list <code>[\"popeye\"]</code> Names of the default plugins   scan.plugins.popeye.enabled bool <code>true</code>    scan.plugins.popeye.image.repository string <code>\"derailed/popeye\"</code> popeye plugin image repository   scan.plugins.popeye.image.tag string <code>\"v0.10.0\"</code> popeye plugin image tag   scan.plugins.kubescape.enabled bool <code>false</code>    scan.plugins.kubescape.image.repository string <code>\"quay.io/armosec/kubescape\"</code> kubescape plugin image repository   scan.plugins.kubescape.image.tag string <code>\"v2.0.163\"</code> kubescape plugin image tag    <p>Specify each parameter using the <code>--set key=value[,key=value]</code> argument to <code>helm install</code>. For example,</p> <pre><code>$ helm install zora \\\n  --set server.service.port=8080 undistro/zora\n</code></pre> <p>Alternatively, a YAML file that specifies the values for the parameters can be provided while installing the chart. For example,</p> <pre><code>$ helm install zora -f values.yaml undistro/zora\n</code></pre>  <p>Tip: You can use the default values.yaml</p>"},{"location":"install/","title":"Install","text":"<p>Zora requires an existing Kubernetes cluster accessible via <code>kubectl</code>. After the installation process this cluster will be your management cluster with the Zora components installed.  So it is recommended to keep it separated from any application workload.</p>"},{"location":"install/#setup-requirements","title":"Setup Requirements","text":"<p>Zora's management cluster requires these programs in order to be installed and configured:</p> <ul> <li>Kubernetes &gt;= 1.21.0</li> <li>Helm &gt;= 3.4.0</li> <li>Kubectl</li> <li>Awk</li> <li>Cat</li> <li>POSIX shell</li> </ul>"},{"location":"install/#install-with-helm","title":"Install with Helm","text":"<ol> <li>To install Zora using Helm follow these commands:</li> </ol> Zora + SaaSZora (kubectl)   <p>In this option you have access to the powerful dashboard to see your clusters and issues.</p>  <p>Warning</p> <p>The SaaS (<code>https://zora-dashboard.undistro.io/</code>) must be reachable by Zora.</p>  <p>1.1 Sign in at https://zora-dashboard.undistro.io/ and select a workspace</p> <p>1.2 Get your workspace ID by clicking on  and provide it by the <code>saas.workspaceID</code> flag:</p> <pre><code>helm repo add undistro https://charts.undistro.io --force-update\nhelm repo update undistro\nhelm upgrade --install zora undistro/zora \\\n  --set saas.workspaceID='&lt;YOUR WORKSPACE ID&gt;'\n  -n zora-system \\\n  --create-namespace --wait\n</code></pre>   <p>In this option you can see your clusters and issues by <code>kubectl</code>.</p> <pre><code>helm repo add undistro https://charts.undistro.io --force-update\nhelm repo update undistro\nhelm upgrade --install zora undistro/zora \\\n  -n zora-system \\\n  --create-namespace --wait\n</code></pre>     <p>Info</p> <p>The Helm chart repository has been updated from <code>https://registry.undistro.io/chartrepo/library</code> to <code>https://charts.undistro.io</code>.</p> <p>The <code>--force-update</code> flag is needed to update the repository URL.</p>  <p>These commands deploy Zora to the Kubernetes cluster. This section lists the parameters that can be configured during installation.</p>"},{"location":"install/#access-to-the-dashboard","title":"Access to the dashboard","text":"<p>If you installed Zora providing a workspace ID (Zora + SaaS),  you have access to the powerful dashboard at https://zora-dashboard.undistro.io/</p> <p>The output of <code>helm install</code> and <code>helm upgrade</code> commands contains the dashboard URL and you can get it anytime by running: </p> <pre><code>helm get notes zora -n zora-system\n</code></pre>"},{"location":"install/#uninstall","title":"Uninstall","text":"<pre><code>helm delete zora -n zora-system\nkubectl delete namespace zora-system\n</code></pre>"},{"location":"target-cluster/","title":"Prepare the target cluster","text":"<p>Follow this guide to create a service account and generate a kubeconfig file from a target cluster. These are the only steps required to be performed in the target cluster.</p> <p>For manual configuration, go to Manual Configuration, otherwise proceed to Setup Script.</p>  <p>Note</p> <p>If your target cluster is under a server proxy for external communication, like those present on platforms like Rancher,  we recommend generating a kubeconfig file through your own platform.</p> <p>Normally these platforms handle their own tokens instead of a service account token.</p> <p>Zora requires read-only access, as described here.</p>"},{"location":"target-cluster/#setup-script","title":"Setup Script","text":"<p>A script is available to prepare a cluster, which can be executed by any POSIX compliant shell. </p> <p>The target cluster context can be set by exporting the <code>CONTEXT</code> variable or switching via <code>kubectl</code>, before running the script:</p> <p><pre><code>curl -q https://zora-docs.undistro.io/v0.4/targetcluster.sh | CONTEXT=&lt;TARGET_CONTEXT&gt; sh\n</code></pre> or <pre><code>kubectl config use-context &lt;TARGET_CONTEXT&gt;\ncurl -q https://zora-docs.undistro.io/v0.4/targetcluster.sh | sh\n</code></pre></p> <p>By default, the generated kubeconfig will be named as your current Kubernetes context suffixed with <code>-kubeconfig.yaml</code>.</p> <p>Before finishing, the script will show a command to connect the target cluster through the generated kubeconfig, and save a sample <code>Cluster</code> manifest.</p> <p>A complete list of customizable environment variables can be seen on the table below.</p>    Environment Variable Description     <code>SVC_ACCOUNT_NS</code> Service Account namespace, defaults to <code>zora-system</code>   <code>SVC_ACCOUNT_NAME</code> Service Account name, defaults to <code>zora-view</code>   <code>CLUSTER_ROLE_NAME</code> Cluster Role name, defaults to <code>zora-view</code>   <code>SVC_ACCOUNT_SECRET_NS</code> Service Account Secret namespace, defaults to the value of <code>SVC_ACCOUNT_NS</code>   <code>SVC_ACCOUNT_SECRET_NAME</code> Service Account Secret name, defaults to the of value of <code>SVC_ACCOUNT_NAME</code> with the \"-token\" suffix   <code>KCONFIG_SECRET_NAME</code> Name of the displayed kubeconfig Secret, defaults to the value of <code>CLUSTER_NAME</code> with the \"-kubeconfig\" suffix   <code>TOKEN_NAME</code> Uses the value of <code>SVC_ACCOUNT_SECRET_NAME</code> or the one generated by K8s, according to the cluster version   <code>CONTEXT</code> K8s context, using the current one as default   <code>CLUSTER_NAME</code> Cluster name from the <code>CONTEXT</code> variable   <code>CLUSTER_NS</code> Cluster namespace used on the manifest sample, defaults to the value of <code>SVC_ACCOUNT_NS</code>   <code>CLUSTER_CA</code> Cluster Certificate Authority, extracted according to <code>CONTEXT</code>   <code>CLUSTER_SERVER</code> Cluster server address, extracted according to <code>CONTEXT</code>   <code>KCONFIG_NAME</code> Name of the generated kubeconfig, defaulting to the value of <code>CONTEXT</code> plus the string \"_kubeconfig.yaml\"   <code>SAMPLE_MANIFEST_NAME</code> Name of the <code>Cluster</code> manifest sample, defaults to <code>cluster_sample.yaml</code> plus the K8s context as prefix    <p>The next instructions explain how to manually configure your target clusters.</p>"},{"location":"target-cluster/#manual-configuration","title":"Manual Configuration","text":"<p>The target cluster can be configured through the steps described in the next sections.</p>"},{"location":"target-cluster/#1-access-the-target-cluster","title":"1. Access the target cluster","text":"<p>First, make sure you are in the context of the target cluster. You can do this by the following commands:</p> <ul> <li> <p>Display list of contexts: <code>kubectl config get-contexts</code></p> </li> <li> <p>Display the current-context: <code>kubectl config current-context</code></p> </li> <li> <p>Set the default context to my-target-cluster: <code>kubectl config use-context my-target-cluster</code></p> </li> </ul>"},{"location":"target-cluster/#2-create-the-rbac-resources","title":"2. Create the RBAC resources","text":"<p>Create the service account in a separate namespace and configure <code>view</code> permissions. The token generated by this service account will be used in the kubeconfig file.</p>  <p>Important</p> <p>You should create a separate service account in the target cluster to connect it to Zora.  This is required because the kubeconfig files generated by most cloud providers,  call CLI commands, such as <code>aws</code> or <code>gcloud</code>, those can\u2019t be called by Zora.</p>  <pre><code>kubectl create namespace zora-system\nkubectl -n zora-system create serviceaccount zora-view\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: zora-view\nrules:\n  - apiGroups: [ \"\" ]\n    resources:\n      - configmaps\n      - endpoints\n      - limitranges\n      - namespaces\n      - nodes\n      - persistentvolumes\n      - persistentvolumeclaims\n      - pods\n      - replicationcontrollers\n      - secrets\n      - serviceaccounts\n      - services\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ \"apps\" ]\n    resources:\n      - daemonsets\n      - deployments\n      - statefulsets\n      - replicasets\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ \"autoscaling\" ]\n    resources:\n      - horizontalpodautoscalers\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ \"networking.k8s.io\" ]\n    resources:\n      - ingresses\n      - networkpolicies\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ \"policy\" ]\n    resources:\n      - poddisruptionbudgets\n      - podsecuritypolicies\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ \"rbac.authorization.k8s.io\" ]\n    resources:\n      - clusterroles\n      - clusterrolebindings\n      - roles\n      - rolebindings\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ \"metrics.k8s.io\" ]\n    resources:\n      - pods\n      - nodes\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ batch ]\n    resources:\n      - jobs\n      - cronjobs\n    verbs: [ \"get\", \"list\" ]\n  - apiGroups: [ admissionregistration.k8s.io ]\n    resources:\n      - validatingwebhookconfigurations\n      - mutatingwebhookconfigurations\n    verbs: [ \"get\", \"list\" ]\nEOF\nkubectl create clusterrolebinding zora-view --clusterrole=zora-view --serviceaccount=zora-system:zora-view\n</code></pre>  <p>Info</p> <p>Zora requires just view permissions of your target clusters.</p>"},{"location":"target-cluster/#3-set-up-the-environment-variables","title":"3. Set up the environment variables","text":"<p>Set up the following environment variables based on the Kubernetes version of the target cluster.</p> <p>You can verify the version of your cluster by running: <pre><code>kubectl version\n</code></pre></p> <p>The Server Version is the version of Kubernetes your target cluster is running.</p> Kubernetes prior to 1.24.0Kubernetes 1.24.0 or later   <pre><code>export TOKEN_NAME=$(kubectl -n zora-system get serviceaccount zora-view -o=jsonpath='{.secrets[0].name}')\nexport TOKEN_VALUE=$(kubectl -n zora-system get secret ${TOKEN_NAME} -o=jsonpath='{.data.token}' | base64 --decode)\nexport CURRENT_CONTEXT=$(kubectl config current-context)\nexport CURRENT_CLUSTER=$(kubectl config view --raw -o=go-template='{{range .contexts}}{{if eq .name \"'''${CURRENT_CONTEXT}'''\"}}{{ index .context \"cluster\" }}{{end}}{{end}}')\nexport CLUSTER_CA=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}\"{{with index .cluster \"certificate-authority-data\" }}{{.}}{{end}}\"{{ end }}{{ end }}')\nexport CLUSTER_SERVER=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}{{ .cluster.server }}{{end}}{{ end }}')\n</code></pre>   <pre><code>export TOKEN_NAME=\"zora-view-token\"\ncat &lt;&lt; EOF | kubectl apply -f - \napiVersion: v1\nkind: Secret\nmetadata:\n    name: \"$TOKEN_NAME\"\n    namespace: \"zora-system\"\n    annotations:\n        kubernetes.io/service-account.name: \"zora-view\"\ntype: kubernetes.io/service-account-token\nEOF\nexport TOKEN_VALUE=$(kubectl -n zora-system get secret ${TOKEN_NAME} -o=jsonpath='{.data.token}' | base64 --decode)\nexport CURRENT_CONTEXT=$(kubectl config current-context)\nexport CURRENT_CLUSTER=$(kubectl config view --raw -o=go-template='{{range .contexts}}{{if eq .name \"'''${CURRENT_CONTEXT}'''\"}}{{ index .context \"cluster\" }}{{end}}{{end}}')\nexport CLUSTER_CA=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}\"{{with index .cluster \"certificate-authority-data\" }}{{.}}{{end}}\"{{ end }}{{ end }}')\nexport CLUSTER_SERVER=$(kubectl config view --raw -o=go-template='{{range .clusters}}{{if eq .name \"'''${CURRENT_CLUSTER}'''\"}}{{ .cluster.server }}{{end}}{{ end }}')\n</code></pre>"},{"location":"target-cluster/#4-generate-a-kubeconfig-file","title":"4. Generate a kubeconfig file","text":"<p>Generate a file with kubeconfig data, based on the environment variables defined before:</p> <pre><code>cat &lt;&lt; EOF &gt; zora-view-kubeconfig.yml\napiVersion: v1\nkind: Config\ncurrent-context: ${CURRENT_CONTEXT}\ncontexts:\n- name: ${CURRENT_CONTEXT}\n  context:\n    cluster: ${CURRENT_CONTEXT}\n    user: zora-view\nclusters:\n- name: ${CURRENT_CONTEXT}\n  cluster:\n    certificate-authority-data: ${CLUSTER_CA}\n    server: ${CLUSTER_SERVER}\nusers:\n- name: zora-view\n  user:\n    token: ${TOKEN_VALUE}\nEOF\n</code></pre>"},{"location":"target-cluster/#verify-the-generated-kubeconfig","title":"Verify the generated kubeconfig","text":"<p>These steps create a file in your current working directory called <code>zora-view-kubeconfig.yml</code>. The contents of this file are used in the next guide to connect this target cluster into Zora.</p> <p>Before using this kubeconfig, you can verify that it is functional by running:</p> <pre><code>kubectl --kubeconfig zora-view-kubeconfig.yml get all --all-namespaces\n</code></pre>"}]}